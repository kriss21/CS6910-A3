{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path) as fil:\n",
    "        data = pd.read_csv(fil,sep='\\t',header=None,names=[\"hi\",\"en\",\"\"],skip_blank_lines=True,index_col=None)\n",
    "    data = data[data['hi'].notna()]\n",
    "    data = data[data['en'].notna()]\n",
    "    data = data[['hi','en']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(\"hi.translit.sampled.train.tsv\")\n",
    "dev = load_data(\"hi.translit.sampled.dev.tsv\")\n",
    "test = load_data(\"hi.translit.sampled.test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['en'].values\n",
    "y = train['hi'].values\n",
    "y = '\\t'+y+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tokens = set()\n",
    "hindi_tokens = set()\n",
    "\n",
    "for xx,yy in zip(x,y):\n",
    "    for ch in xx:\n",
    "        english_tokens.add(ch)\n",
    "    for ch in yy:\n",
    "        hindi_tokens.add(ch)\n",
    "    \n",
    "english_tokens = sorted(list(english_tokens))\n",
    "hindi_tokens = sorted(list(hindi_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_token_map = dict([(ch,i+1) for i,ch in enumerate(english_tokens)])\n",
    "hin_token_map = dict([(ch,i+1) for i,ch in enumerate(hindi_tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hin_token_map[\" \"] = 0\n",
    "eng_token_map[\" \"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_len = max([len(i) for i in x])\n",
    "max_hin_len = max([len(i) for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    x,y = data['en'].values, data['hi'].values\n",
    "    y = \"\\t\" + y + \"\\n\"\n",
    "    \n",
    "    a = np.zeros((len(x),max_eng_len),dtype=\"float32\")\n",
    "    b = np.zeros((len(y),max_hin_len),dtype=\"float32\")\n",
    "    c = np.zeros((len(y),max_hin_len,len(hindi_tokens)+1),dtype=\"int\")\n",
    "    \n",
    "    \n",
    "    for i,(xx,yy) in enumerate(zip(x,y)):\n",
    "        for j,ch in enumerate(xx):\n",
    "            a[i,j] = eng_token_map[ch]\n",
    "\n",
    "        a[i,j+1:] = eng_token_map[\" \"]\n",
    "        for j,ch in enumerate(yy):\n",
    "            b[i,j] = hin_token_map[ch]\n",
    "\n",
    "            if j>0:\n",
    "                c[i,j-1,hin_token_map[ch]] = 1\n",
    "\n",
    "        b[i,j+1:] = hin_token_map[\" \"]\n",
    "        c[i,j:,hin_token_map[\" \"]] = 1\n",
    "        \n",
    "    return a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx,testxx,testy = process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_eng_map = dict([(i,char) for char,i in eng_token_map.items()])\n",
    "reverse_hin_map = dict([(i,char) for char,i in hin_token_map.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import SimpleRNN,LSTM,GRU,Embedding,Dense,Dropout,Input\n",
    "from keras.optimizers import Adam,Nadam\n",
    "from keras import Model\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bce91f6a6599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "enc = keras.models.load_model('best_enc.h5')\n",
    "dec = keras.models.load_model('best_dec.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(inp,k,dec_layers,cell=\"LSTM\"):\n",
    "    statess = enc.predict(inp)\n",
    "    print(\"encoder done\")\n",
    "    target_seq = np.zeros((inp.shape[0],1))\n",
    "    target_seq[:,0] = hin_token_map[\"\\t\"]\n",
    "    if cell == \"LSTM\":\n",
    "        states = []\n",
    "        for i in range(dec_layers):\n",
    "            states += [statess[0],statess[1]]\n",
    "    else:\n",
    "        states = []\n",
    "        for i in range(dec_layers):\n",
    "            states += [statess]\n",
    "            \n",
    "    output = dec.predict([target_seq]+states)\n",
    "    states = output[1:]\n",
    "    \n",
    "    stat1 = np.asarray(states).transpose([1,0,2])\n",
    "    \n",
    "    best_chars = np.argsort(output[0][:,-1,:],axis=-1)[:,-k:]\n",
    "    scores = np.sort(output[0][:,-1,:],axis=-1)[:,-k:]\n",
    "    sequences = [[([ch],-np.log(sc),stat1[i],0) for ch,sc in zip(best_chars[i],scores[i])] for i in range(inp.shape[0])]\n",
    "    \n",
    "    \n",
    "    for t1 in range(max_hin_len-1):\n",
    "        candidates = [[] for _ in range(inp.shape[0])]\n",
    "        for j in range(k):\n",
    "            target_seq[:,0] = [sequences[i][j][0][-1] for i in range(inp.shape[0])]\n",
    "            states = list(np.asarray([sequences[i][j][2] for i in range(inp.shape[0])]).transpose([1,0,2]))\n",
    "            output = dec.predict([target_seq]+states,batch_size=32)\n",
    "            best_chars = np.argsort(output[0][:,-1,:],axis=-1)[:,-k:]\n",
    "            scores = np.sort(output[0][:,-1,:],axis=-1)[:,-k:]\n",
    "            \n",
    "            stat1 = np.asarray(output[1:]).transpose([1,0,2])\n",
    "            \n",
    "            for i in range(inp.shape[0]):\n",
    "                chk = 1 if (sequences[i][j][3]==1 or sequences[i][j][0][-1] == hin_token_map[\"\\n\"]) else 0\n",
    "                if chk == 0:\n",
    "                    candidates[i] += [(sequences[i][j][0]+[best_chars[i,rep]],\n",
    "                                       sequences[i][j][1]-np.log(scores[i,rep]),\n",
    "                                       stat1[i],chk)\n",
    "                                      for rep in range(k)]\n",
    "                else:\n",
    "                    candidates[i] += [sequences[i][j]]\n",
    "                    \n",
    "        for i in range(inp.shape[0]):\n",
    "            candidates[i] = sorted(candidates[i],key = lambda tup:tup[1]/len(tup[0]))\n",
    "            sequences[i] = candidates[i][:k]\n",
    "            \n",
    "        print(f\"decoder {t1} done\")\n",
    "            \n",
    "        \n",
    "    res = [list() for i in range(inp.shape[0])]\n",
    "    for i in range(inp.shape[0]):\n",
    "        for j in range(k):\n",
    "            res[i].append(sequences[i][j][0])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder done\n",
      "decoder 0 done\n",
      "decoder 1 done\n",
      "decoder 2 done\n",
      "decoder 3 done\n",
      "decoder 4 done\n",
      "decoder 5 done\n",
      "decoder 6 done\n",
      "decoder 7 done\n",
      "decoder 8 done\n",
      "decoder 9 done\n",
      "decoder 10 done\n",
      "decoder 11 done\n",
      "decoder 12 done\n",
      "decoder 13 done\n",
      "decoder 14 done\n",
      "decoder 15 done\n",
      "decoder 16 done\n",
      "decoder 17 done\n",
      "decoder 18 done\n",
      "decoder 19 done\n",
      "38.40921425819397\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pred1 = beam_search(testx,5,3,cell=\"LSTM\")\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(inp,dec_layers,cell=\"LSTM\"):\n",
    "    statess = enc.predict(inp)\n",
    "    target_seq = np.zeros((inp.shape[0],1))\n",
    "    target_seq[:,0] = hin_token_map[\"\\t\"]\n",
    "    \n",
    "    states = []\n",
    "    \n",
    "    if cell == \"LSTM\":\n",
    "        for c in range(dec_layers):\n",
    "            states += [statess[0],statess[1]]\n",
    "            \n",
    "    else:\n",
    "        for c in range(dec_layers):\n",
    "            states += [statess]\n",
    "            \n",
    "    ans = np.zeros((inp.shape[0],max_hin_len))\n",
    "    \n",
    "    for i in range(max_hin_len):\n",
    "        output = dec.predict([target_seq]+states,batch_size=64)\n",
    "        ans[:,i] = np.argmax(output[0][:,-1,:],axis=1)\n",
    "        target_seq[:,0] = ans[:,i]\n",
    "        states = output[1:]\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = inference(testx,3,cell=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English word: purjon              \n",
      "Decoded word: पुरजों\n",
      "\n",
      "Decoded beam word: पुरजों\n",
      "\n",
      "Decoded beam word: पुर्जों\n",
      "\n",
      "Decoded beam word: पूरजों\n",
      "\n",
      "Decoded beam word: पूर्जों\n",
      "\n",
      "Decoded beam word: पर्जों\n",
      "\n",
      "Hindi original: पुर्जों\n",
      "\n",
      "=========\n",
      "English word: peratrupers         \n",
      "Decoded word: पैरार्ड्रपर्स\n",
      "\n",
      "Decoded beam word: पैरार्टपर्स\n",
      "\n",
      "Decoded beam word: पैरारफर्स\n",
      "\n",
      "Decoded beam word: पैराटरप्र्स\n",
      "\n",
      "Decoded beam word: पैरार्ड्रपर्स\n",
      "\n",
      "Decoded beam word: पैरार्डर्प्स\n",
      "\n",
      "Hindi original: पैराट्रूपर\n",
      "\n",
      "=========\n",
      "English word: chaupal             \n",
      "Decoded word: चौपाल\n",
      "\n",
      "Decoded beam word: चौपाल\n",
      "\n",
      "Decoded beam word: चौपल\n",
      "\n",
      "Decoded beam word: छौपाल\n",
      "\n",
      "Decoded beam word: छौपल\n",
      "\n",
      "Decoded beam word: चाउपल\n",
      "\n",
      "Hindi original: चौपाल\n",
      "\n",
      "=========\n",
      "English word: raak                \n",
      "Decoded word: राक\n",
      "\n",
      "Decoded beam word: राक\n",
      "\n",
      "Decoded beam word: रक\n",
      "\n",
      "Decoded beam word: राक़\n",
      "\n",
      "Decoded beam word: रॉक\n",
      "\n",
      "Decoded beam word: रैक\n",
      "\n",
      "Hindi original: राक\n",
      "\n",
      "=========\n",
      "English word: saleeb              \n",
      "Decoded word: सलीब\n",
      "\n",
      "Decoded beam word: सलीब\n",
      "\n",
      "Decoded beam word: सालीब\n",
      "\n",
      "Decoded beam word: स्लेबि\n",
      "\n",
      "Decoded beam word: सालिब\n",
      "\n",
      "Decoded beam word: सेलीब\n",
      "\n",
      "Hindi original: सलीब\n",
      "\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    idx = np.random.choice(testx.shape[0])\n",
    "    orig = \"\"\n",
    "    for ch in testx[idx]:\n",
    "        orig += reverse_eng_map[ch]\n",
    "        if reverse_eng_map[ch] == \"\\n\":\n",
    "            break\n",
    "    print(\"English word:\",orig)\n",
    "        \n",
    "    deco = \"\"\n",
    "    for ch in pred[idx]:\n",
    "        deco += reverse_hin_map[ch]\n",
    "        if reverse_hin_map[ch] == \"\\n\":\n",
    "            break\n",
    "            \n",
    "    print(\"Decoded word:\", deco)\n",
    "    \n",
    "    for pr in pred1[idx]:\n",
    "        deco1 = \"\"\n",
    "        for ch in pr:\n",
    "            deco1 += reverse_hin_map[ch]\n",
    "            if reverse_hin_map[ch] == \"\\n\":\n",
    "                break\n",
    "        \n",
    "        print(\"Decoded beam word:\", deco1)\n",
    "            \n",
    "    hind = \"\"\n",
    "    for ch in testxx[idx]:\n",
    "        hind += reverse_hin_map[ch]\n",
    "        if reverse_hin_map[ch] == \"\\n\":\n",
    "            break\n",
    "        \n",
    "    print(\"Hindi original:\",hind[1:])\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3858285206574856\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for i,pr in enumerate(pred):\n",
    "    fl = 1\n",
    "    for j,ch in enumerate(pr):\n",
    "        if ch != np.argmax(testy[i,j,:]):\n",
    "            fl = 0\n",
    "            break\n",
    "        if ch == hin_token_map[\"\\n\"]:\n",
    "            break\n",
    "            \n",
    "    if fl==1:\n",
    "        acc+=1\n",
    "        \n",
    "        \n",
    "print(acc/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7145713016437139\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for i,pre in enumerate(pred1):\n",
    "    chk = 0\n",
    "    \n",
    "    for pr in pre:\n",
    "        fl = 1\n",
    "        for j,ch in enumerate(pr):\n",
    "            if ch!=np.argmax(testy[i,j,:]):\n",
    "                fl=0\n",
    "                break\n",
    "            if ch==hin_token_map[\"\\n\"]:\n",
    "                break\n",
    "        chk = chk or fl\n",
    "        \n",
    "    if chk==1:\n",
    "        acc+=1\n",
    "        \n",
    "        \n",
    "print(acc/len(pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "ans1 = []\n",
    "\n",
    "for i,pre in enumerate(pred1):\n",
    "    word = []\n",
    "    word1 = []\n",
    "    \n",
    "    orig = \"\"\n",
    "    for ch in testx[i]:\n",
    "        if reverse_eng_map[ch] == \" \":\n",
    "            break\n",
    "        orig += reverse_eng_map[ch]\n",
    "    word.append(orig)\n",
    "    word1.append(orig)\n",
    "    \n",
    "    hind = \"\"\n",
    "    for ch in testxx[i,1:]:\n",
    "        if reverse_hin_map[ch] == \"\\n\":\n",
    "            break\n",
    "        hind += reverse_hin_map[ch]\n",
    "    \n",
    "    word.append(hind)\n",
    "    word1.append(hind)\n",
    "    \n",
    "    for j,pr in enumerate(pre):\n",
    "        deco1 = \"\"\n",
    "        for ch in pr:\n",
    "            if reverse_hin_map[ch] == \"\\n\":\n",
    "                break\n",
    "            deco1 += reverse_hin_map[ch]\n",
    "        word.append(deco1)\n",
    "        if j==0:\n",
    "            word1.append(deco1)\n",
    "        \n",
    "    ans.append(word)\n",
    "    ans1.append(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Hindi_pred_0</th>\n",
       "      <th>Hindi_pred_1</th>\n",
       "      <th>Hindi_pred_2</th>\n",
       "      <th>Hindi_pred_3</th>\n",
       "      <th>Hindi_pred_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>shervasiyon</td>\n",
       "      <td>शहरवासियों</td>\n",
       "      <td>शेर्वासियों</td>\n",
       "      <td>शेरवासियों</td>\n",
       "      <td>क्षेरवाजियों</td>\n",
       "      <td>शर्वासियों</td>\n",
       "      <td>शेर्वायियोजन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>pigmentation</td>\n",
       "      <td>पिगमेंटेशन</td>\n",
       "      <td>पिक्सेनेशन</td>\n",
       "      <td>पिग्मेंटेशन</td>\n",
       "      <td>पिग्लेशनेशन</td>\n",
       "      <td>पिग्लेस्थेनियन</td>\n",
       "      <td>पिग्लेशनेटन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>khinchakar</td>\n",
       "      <td>खिंचकर</td>\n",
       "      <td>खिंचाकार</td>\n",
       "      <td>खींचाकार</td>\n",
       "      <td>खींचकार</td>\n",
       "      <td>खींचकर</td>\n",
       "      <td>खिंचकर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>loge</td>\n",
       "      <td>लोगे</td>\n",
       "      <td>लोगे</td>\n",
       "      <td>लोज</td>\n",
       "      <td>लोग</td>\n",
       "      <td>लॉज</td>\n",
       "      <td>लॉग</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>adhyaynrat</td>\n",
       "      <td>अध्ययनरत</td>\n",
       "      <td>अध्ययंत्र</td>\n",
       "      <td>अध्ययंत्राव</td>\n",
       "      <td>अध्ययन्रत</td>\n",
       "      <td>अध्ययंत्राद</td>\n",
       "      <td>अध्ययंत्रा</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           English       Hindi Hindi_pred_0 Hindi_pred_1  Hindi_pred_2  \\\n",
       "3910   shervasiyon  शहरवासियों  शेर्वासियों   शेरवासियों  क्षेरवाजियों   \n",
       "2338  pigmentation  पिगमेंटेशन   पिक्सेनेशन  पिग्मेंटेशन   पिग्लेशनेशन   \n",
       "938     khinchakar      खिंचकर     खिंचाकार     खींचाकार       खींचकार   \n",
       "3676          loge        लोगे         लोगे          लोज           लोग   \n",
       "83      adhyaynrat    अध्ययनरत    अध्ययंत्र  अध्ययंत्राव     अध्ययन्रत   \n",
       "\n",
       "        Hindi_pred_3  Hindi_pred_4  \n",
       "3910      शर्वासियों  शेर्वायियोजन  \n",
       "2338  पिग्लेस्थेनियन   पिग्लेशनेटन  \n",
       "938           खींचकर        खिंचकर  \n",
       "3676             लॉज           लॉग  \n",
       "83       अध्ययंत्राद    अध्ययंत्रा  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ans,columns=['English','Hindi']+[f'Hindi_pred_{i}' for i in range(5)])\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('predictions_vanilla_beam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "      <th>Hindi_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>nigar</td>\n",
       "      <td>निगर</td>\n",
       "      <td>निगार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>kaagaz</td>\n",
       "      <td>कागज़</td>\n",
       "      <td>काग़ज़</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>shawn</td>\n",
       "      <td>शॉन</td>\n",
       "      <td>शावन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>bosten</td>\n",
       "      <td>बॉस्टन</td>\n",
       "      <td>बॉस्टन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>colan</td>\n",
       "      <td>कोलन</td>\n",
       "      <td>कोलन</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     English   Hindi Hindi_pred\n",
       "2090   nigar    निगर      निगार\n",
       "762   kaagaz   कागज़     काग़ज़\n",
       "3955   shawn     शॉन       शावन\n",
       "2896  bosten  बॉस्टन     बॉस्टन\n",
       "859    colan    कोलन       कोलन"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(ans1,columns=['English','Hindi','Hindi_pred'])\n",
    "df1.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('predictions_vanilla.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
