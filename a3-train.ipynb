{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6VgLpCUITeG0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path) as fil:\n",
    "        data = pd.read_csv(fil,sep='\\t',header=None,names=[\"hi\",\"en\",\"\"],skip_blank_lines=True,index_col=None)\n",
    "    data = data[data['hi'].notna()]\n",
    "    data = data[data['en'].notna()]\n",
    "    data = data[['hi','en']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4OFs4DvTTtPB"
   },
   "outputs": [],
   "source": [
    "train = load_data(\"hi.translit.sampled.train.tsv\")\n",
    "dev = load_data(\"hi.translit.sampled.dev.tsv\")\n",
    "test = load_data(\"hi.translit.sampled.test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "0-JF8OnET2FL",
    "outputId": "8f50fcf7-a9f1-4f2f-85d2-021f84b07161"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अं</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>अंकगणित</td>\n",
       "      <td>ankganit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>अंकल</td>\n",
       "      <td>uncle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>अंकुर</td>\n",
       "      <td>ankur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>अंकुरण</td>\n",
       "      <td>ankuran</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hi        en\n",
       "0       अं        an\n",
       "1  अंकगणित  ankganit\n",
       "2     अंकल     uncle\n",
       "3    अंकुर     ankur\n",
       "4   अंकुरण   ankuran"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dqIMqB6cT2xE"
   },
   "outputs": [],
   "source": [
    "x = train['en'].values\n",
    "y = train['hi'].values\n",
    "y = '\\t'+y+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bEnBqQAqT5h-"
   },
   "outputs": [],
   "source": [
    "english_tokens = set()\n",
    "hindi_tokens = set()\n",
    "\n",
    "for xx,yy in zip(x,y):\n",
    "    for ch in xx:\n",
    "        english_tokens.add(ch)\n",
    "    for ch in yy:\n",
    "        hindi_tokens.add(ch)\n",
    "    \n",
    "english_tokens = sorted(list(english_tokens))\n",
    "hindi_tokens = sorted(list(hindi_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p1Bph1kNT6wA"
   },
   "outputs": [],
   "source": [
    "eng_token_map = dict([(ch,i+1) for i,ch in enumerate(english_tokens)])\n",
    "hin_token_map = dict([(ch,i+1) for i,ch in enumerate(hindi_tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hin_token_map[\" \"] = 0\n",
    "eng_token_map[\" \"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PxgxWQwnT8D3"
   },
   "outputs": [],
   "source": [
    "max_eng_len = max([len(i) for i in x])\n",
    "max_hin_len = max([len(i) for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    x,y = data['en'].values, data['hi'].values\n",
    "    y = \"\\t\" + y + \"\\n\"\n",
    "    \n",
    "    a = np.zeros((len(x),max_eng_len),dtype=\"float32\")\n",
    "    b = np.zeros((len(y),max_hin_len),dtype=\"float32\")\n",
    "    c = np.zeros((len(y),max_hin_len,len(hindi_tokens)+1),dtype=\"int\")\n",
    "    \n",
    "    \n",
    "    for i,(xx,yy) in enumerate(zip(x,y)):\n",
    "        for j,ch in enumerate(xx):\n",
    "            a[i,j] = eng_token_map[ch]\n",
    "\n",
    "        a[i,j+1:] = eng_token_map[\" \"]\n",
    "        for j,ch in enumerate(yy):\n",
    "            b[i,j] = hin_token_map[ch]\n",
    "\n",
    "            if j>0:\n",
    "                c[i,j-1,hin_token_map[ch]] = 1\n",
    "\n",
    "        b[i,j+1:] = hin_token_map[\" \"]\n",
    "        c[i,j:,hin_token_map[\" \"]] = 1\n",
    "        \n",
    "    return a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a8FMzKqvT9eA"
   },
   "outputs": [],
   "source": [
    "trainx, trainxx, trainy = process(train)\n",
    "valx, valxx, valy = process(dev)\n",
    "testx,testxx,testy = process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VNWQZNUCUHtL"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_eng_map = dict([(i,char) for char,i in eng_token_map.items()])\n",
    "reverse_hin_map = dict([(i,char) for char,i in hin_token_map.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import SimpleRNN,LSTM,GRU,Embedding,Dense,Dropout,Input\n",
    "from keras.optimizers import Adam,Nadam\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cell = \"LSTM\",nunits = 32, enc_layers = 1, dec_layers = 1,embed_dim = 32,dense_size=32,dropout=None):\n",
    "    keras.backend.clear_session()\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    encoder_embedding = Embedding(input_dim=len(english_tokens)+1,output_dim = embed_dim,mask_zero=True,name=\"enc_embed\")\n",
    "    encoder_context = encoder_embedding(encoder_inputs)\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    decoder_embedding = Embedding(input_dim = len(hindi_tokens)+1,output_dim = embed_dim,mask_zero=True,name=\"dec_embed\")\n",
    "    decoder_context = decoder_embedding(decoder_inputs)\n",
    "    \n",
    "    if cell == \"LSTM\":\n",
    "        encoder_prev = [LSTM(nunits,return_sequences=True,name=f\"enc_{i}\") for i in range(enc_layers-1)]\n",
    "        encoder_fin = LSTM(nunits,return_state=True,name=f\"enc_{enc_layers-1}\")\n",
    "        temp = encoder_context\n",
    "        for i,lay in enumerate(encoder_prev):\n",
    "            temp = lay(temp)\n",
    "            if dropout is not None:\n",
    "                temp = Dropout(dropout,name=f\"do_{i}\")(temp)\n",
    "            \n",
    "        _, state_h,state_c = encoder_fin(temp)\n",
    "        encoder_states = [state_h,state_c]\n",
    "        \n",
    "        decoder = [LSTM(nunits,return_sequences=True,return_state=True,name=f\"dec_{i}\") for i in range(dec_layers)]\n",
    "        \n",
    "        temp,sh,sc = decoder[0](decoder_context,initial_state=encoder_states)\n",
    "        for i in range(1,dec_layers):\n",
    "            temp,sh,sc = decoder[i](temp,initial_state=encoder_states)\n",
    "            \n",
    "    elif cell == \"Simple\":\n",
    "        encoder_prev = [SimpleRNN(nunits,return_sequences=True,name=f\"enc_{i}\") for i in range(enc_layers-1)]\n",
    "        encoder_fin = SimpleRNN(nunits,return_state=True,name=f\"enc_{enc_layers-1}\")\n",
    "        temp = encoder_context\n",
    "        for i,lay in enumerate(encoder_prev):\n",
    "            temp = lay(temp)\n",
    "            if dropout is not None:\n",
    "                temp = Dropout(dropout,name=f\"do_{i}\")(temp)\n",
    "            \n",
    "        _, state = encoder_fin(temp)\n",
    "        encoder_states = state\n",
    "        \n",
    "        decoder = [SimpleRNN(nunits,return_sequences=True,return_state=True,name=f\"dec_{i}\") for i in range(dec_layers)]\n",
    "        \n",
    "        temp,s = decoder[0](decoder_context,initial_state=state)\n",
    "        for i in range(1,dec_layers):\n",
    "            temp,s = decoder[i](temp,initial_state=state)\n",
    "       \n",
    "    elif cell == \"GRU\":\n",
    "        encoder_prev = [GRU(nunits,return_sequences=True,name=f\"enc_{i}\") for i in range(enc_layers-1)]\n",
    "        encoder_fin = GRU(nunits,return_state=True,name=f\"enc_{enc_layers-1}\")\n",
    "        temp = encoder_context\n",
    "        for i,lay in enumerate(encoder_prev):\n",
    "            temp = lay(temp)\n",
    "            if dropout is not None:\n",
    "                temp = Dropout(dropout,name=f\"do_{i}\")(temp)\n",
    "            \n",
    "        _, state = encoder_fin(temp)\n",
    "        encoder_states = state\n",
    "        \n",
    "        decoder = [GRU(nunits,return_sequences=True,return_state=True,name=f\"dec_{i}\") for i in range(dec_layers)]\n",
    "        \n",
    "        temp,s = decoder[0](decoder_context,initial_state=state)\n",
    "        for i in range(1,dec_layers):\n",
    "            temp,s = decoder[i](temp,initial_state=state)\n",
    "            \n",
    "        \n",
    "    dense_lay1 = Dense(dense_size,activation='relu',name='dense1')\n",
    "    pre_out = dense_lay1(temp)\n",
    "    dense_lay2 = Dense(len(hindi_tokens)+1,activation = 'softmax',name='dense2')\n",
    "    final_output = dense_lay2(pre_out)\n",
    "    \n",
    "    train = Model([encoder_inputs,decoder_inputs],final_output)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy1(real,pred):\n",
    "    real = tf.math.argmax(real,axis=2)\n",
    "    pred = tf.math.argmax(pred,axis=2)\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    acc = tf.math.equal(real,pred)\n",
    "    mask = tf.cast(mask, dtype='int32')\n",
    "    acc = tf.cast(acc, dtype='int32')\n",
    "    acc = tf.math.multiply(acc,mask)\n",
    "    mask = tf.reduce_sum(mask,axis=1)\n",
    "    acc = tf.reduce_sum(acc,axis=1)\n",
    "    acc = tf.math.equal(acc,mask)\n",
    "    acc = tf.cast(acc, dtype='float32')\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = build_model(nunits=256,\n",
    "                                dense_size=512,\n",
    "                                enc_layers=3,\n",
    "                                dec_layers=1,\n",
    "                                cell = \"LSTM\",\n",
    "                                dropout = 0.2,\n",
    "                                embed_dim = 256)\n",
    "train.compile(optimizer = Adam(lr=1e-3),loss='categorical_crossentropy',metrics=[accuracy1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cb = tf.keras.callbacks.ModelCheckpoint('best_model.h5',monitor='val_accuracy1',mode='max',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.7248 - accuracy1: 0.0154\n",
      "Epoch 00001: val_accuracy1 improved from -inf to 0.07420, saving model to best_model.h5\n",
      "691/691 [==============================] - 20s 29ms/step - loss: 0.7248 - accuracy1: 0.0154 - val_loss: 0.3741 - val_accuracy1: 0.0742\n",
      "Epoch 2/20\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy1: 0.1911\n",
      "Epoch 00002: val_accuracy1 improved from 0.07420 to 0.27876, saving model to best_model.h5\n",
      "691/691 [==============================] - 17s 25ms/step - loss: 0.2738 - accuracy1: 0.1912 - val_loss: 0.2020 - val_accuracy1: 0.2788\n",
      "Epoch 3/20\n",
      "689/691 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy1: 0.3230\n",
      "Epoch 00003: val_accuracy1 improved from 0.27876 to 0.31997, saving model to best_model.h5\n",
      "691/691 [==============================] - 17s 25ms/step - loss: 0.1761 - accuracy1: 0.3231 - val_loss: 0.1720 - val_accuracy1: 0.3200\n",
      "Epoch 4/20\n",
      "689/691 [============================>.] - ETA: 0s - loss: 0.1365 - accuracy1: 0.4046\n",
      "Epoch 00004: val_accuracy1 improved from 0.31997 to 0.35417, saving model to best_model.h5\n",
      "691/691 [==============================] - 17s 25ms/step - loss: 0.1365 - accuracy1: 0.4047 - val_loss: 0.1560 - val_accuracy1: 0.3542\n",
      "Epoch 5/20\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy1: 0.4693\n",
      "Epoch 00005: val_accuracy1 improved from 0.35417 to 0.38338, saving model to best_model.h5\n",
      "691/691 [==============================] - 17s 25ms/step - loss: 0.1124 - accuracy1: 0.4692 - val_loss: 0.1494 - val_accuracy1: 0.3834\n",
      "Epoch 6/20\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy1: 0.5241\n",
      "Epoch 00006: val_accuracy1 did not improve from 0.38338\n",
      "691/691 [==============================] - 17s 24ms/step - loss: 0.0944 - accuracy1: 0.5242 - val_loss: 0.1511 - val_accuracy1: 0.3681\n",
      "Epoch 7/20\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy1: 0.5711\n",
      "Epoch 00007: val_accuracy1 improved from 0.38338 to 0.38987, saving model to best_model.h5\n",
      "691/691 [==============================] - 17s 24ms/step - loss: 0.0806 - accuracy1: 0.5713 - val_loss: 0.1491 - val_accuracy1: 0.3899\n",
      "Epoch 8/20\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.0697 - accuracy1: 0.6092\n",
      "Epoch 00008: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 24ms/step - loss: 0.0697 - accuracy1: 0.6092 - val_loss: 0.1569 - val_accuracy1: 0.3727\n",
      "Epoch 9/20\n",
      "689/691 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy1: 0.6472\n",
      "Epoch 00009: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 25ms/step - loss: 0.0604 - accuracy1: 0.6475 - val_loss: 0.1622 - val_accuracy1: 0.3891\n",
      "Epoch 10/20\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy1: 0.6753\n",
      "Epoch 00010: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 24ms/step - loss: 0.0536 - accuracy1: 0.6752 - val_loss: 0.1696 - val_accuracy1: 0.3742\n",
      "Epoch 11/20\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy1: 0.7021\n",
      "Epoch 00011: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 18s 26ms/step - loss: 0.0479 - accuracy1: 0.7022 - val_loss: 0.1742 - val_accuracy1: 0.3762\n",
      "Epoch 12/20\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.0429 - accuracy1: 0.7263\n",
      "Epoch 00012: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 24ms/step - loss: 0.0429 - accuracy1: 0.7263 - val_loss: 0.1805 - val_accuracy1: 0.3848\n",
      "Epoch 13/20\n",
      "689/691 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy1: 0.7456\n",
      "Epoch 00013: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 24ms/step - loss: 0.0393 - accuracy1: 0.7458 - val_loss: 0.1875 - val_accuracy1: 0.3780\n",
      "Epoch 14/20\n",
      "689/691 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy1: 0.7651\n",
      "Epoch 00014: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 18s 27ms/step - loss: 0.0361 - accuracy1: 0.7649 - val_loss: 0.1895 - val_accuracy1: 0.3713\n",
      "Epoch 15/20\n",
      "690/691 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy1: 0.7793\n",
      "Epoch 00015: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 24ms/step - loss: 0.0342 - accuracy1: 0.7792 - val_loss: 0.1911 - val_accuracy1: 0.3779\n",
      "Epoch 16/20\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.0319 - accuracy1: 0.7908\n",
      "Epoch 00016: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 18s 27ms/step - loss: 0.0319 - accuracy1: 0.7908 - val_loss: 0.1988 - val_accuracy1: 0.3819\n",
      "Epoch 17/20\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.0303 - accuracy1: 0.7995\n",
      "Epoch 00017: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 24ms/step - loss: 0.0303 - accuracy1: 0.7995 - val_loss: 0.2023 - val_accuracy1: 0.3668\n",
      "Epoch 18/20\n",
      "689/691 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy1: 0.8084\n",
      "Epoch 00018: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 18s 27ms/step - loss: 0.0293 - accuracy1: 0.8082 - val_loss: 0.2025 - val_accuracy1: 0.3637\n",
      "Epoch 19/20\n",
      "689/691 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy1: 0.8183\n",
      "Epoch 00019: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 25ms/step - loss: 0.0278 - accuracy1: 0.8180 - val_loss: 0.2126 - val_accuracy1: 0.3532\n",
      "Epoch 20/20\n",
      "691/691 [==============================] - ETA: 0s - loss: 0.0271 - accuracy1: 0.8222\n",
      "Epoch 00020: val_accuracy1 did not improve from 0.38987\n",
      "691/691 [==============================] - 17s 25ms/step - loss: 0.0271 - accuracy1: 0.8222 - val_loss: 0.2095 - val_accuracy1: 0.3727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe24476a460>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.fit([trainx,trainxx],trainy,\n",
    "             batch_size=64,\n",
    "             validation_data = ([valx,valxx],valy),\n",
    "             epochs=20,\n",
    "             callbacks = [model_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('best_model.h5',custom_objects={'accuracy1':accuracy1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_models(model,nunits=32,enc_layers=1,dec_layers=1,cell='LSTM',dropout=None):\n",
    "    encoder_inputs = model.input[0]\n",
    "    encoder_embedding = model.get_layer('enc_embed')\n",
    "    encoder_context = encoder_embedding(encoder_inputs)\n",
    "    decoder_inputs = model.input[1]\n",
    "    decoder_embedding = model.get_layer('dec_embed')\n",
    "    decoder_context = decoder_embedding(decoder_inputs)\n",
    "    \n",
    "    \n",
    "    encoder_prev = [model.get_layer(f'enc_{i}') for i in range(enc_layers-1)]\n",
    "    encoder_fin = model.get_layer(f'enc_{enc_layers-1}')\n",
    "    temp = encoder_context\n",
    "    for i,lay in enumerate(encoder_prev):\n",
    "        temp = lay(temp)\n",
    "        if dropout is not None:\n",
    "            temp = model.get_layer(f'do_{i}')(temp)\n",
    "     \n",
    "    if cell == \"LSTM\":\n",
    "        _, state_h,state_c = encoder_fin(temp)\n",
    "        encoder_states = [state_h,state_c]\n",
    "        \n",
    "    elif cell == \"GRU\":\n",
    "        _, state = encoder_fin(temp)\n",
    "        encoder_states = state\n",
    "\n",
    "    encoder_model = keras.models.Model(encoder_inputs,encoder_states)\n",
    "    \n",
    "    \n",
    "    \n",
    "    decoder = [model.get_layer(f'dec_{i}') for i in range(dec_layers)]\n",
    "\n",
    "    if cell == \"LSTM\":\n",
    "        state_inputs = []\n",
    "        state_outputs = []\n",
    "\n",
    "        decoder_input_h = Input(shape=(nunits,),name='inputh0')\n",
    "        decoder_input_c = Input(shape=(nunits,),name='inputc0')\n",
    "        temp,sh,sc = decoder[0](decoder_context,initial_state = [decoder_input_h,decoder_input_c])\n",
    "        state_inputs += [decoder_input_h,decoder_input_c]\n",
    "        state_outputs += [sh,sc]\n",
    "\n",
    "        for i in range(1,dec_layers):\n",
    "            decoder_input_h = Input(shape=(nunits,),name=f'inputh{i}')\n",
    "            decoder_input_c = Input(shape=(nunits,),name=f'inputc{i}')\n",
    "            temp,sh,sc = decoder[i](temp,initial_state = [decoder_input_h,decoder_input_c])\n",
    "            state_inputs += [decoder_input_h,decoder_input_c]\n",
    "            state_outputs += [sh,sc]\n",
    "\n",
    "        decoder_input_pass = [decoder_inputs] + state_inputs\n",
    "\n",
    "    elif cell == \"GRU\":\n",
    "        state_inputs = []\n",
    "        state_outputs = []\n",
    "\n",
    "        state_input = Input(shape=(nunits,),name='inputs0')\n",
    "        temp,s = decoder[0](decoder_context,initial_state = state_input)\n",
    "        state_inputs.append(state_input)\n",
    "        state_outputs.append(s)\n",
    "\n",
    "        for i in range(1,dec_layers):\n",
    "            state_input = Input(shape=(nunits,),name=f'inputs{i}')\n",
    "            temp,s = decoder[i](temp,initial_state = state_input)\n",
    "            state_inputs.append(state_input)\n",
    "            state_outputs.append(s)\n",
    "\n",
    "        decoder_input_pass = [decoder_inputs] + state_inputs\n",
    "\n",
    "    pre_out = model.get_layer('dense1')(temp)\n",
    "    final_output = model.get_layer('dense2')(pre_out)\n",
    "\n",
    "    decoder_model = keras.models.Model(decoder_input_pass, [final_output]+state_outputs)\n",
    "    \n",
    "    return encoder_model,decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc,dec = inference_models(model,nunits=256,enc_layers=3,dec_layers=1,cell=\"LSTM\",dropout='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.save('best_enc.h5')\n",
    "dec.save('best_dec.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CS6910-assignment3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
